---
id: T-C01
title: "[data] Extrair coment√°rios para JSON e ajustar consist√™ncia de documentos ‚Äî Sem salvar no banco de dados"
status: completed
created: 2025-09-10
updated: 2025-09-11
owner: "@iuryeng"
reviewers: ["@iuryeng"]
labels: ["area/data", "type/feat"]
priority: high
effort: L
risk: low
depends_on: []
related: []
epic: "Fase 3: Scraping Avan√ßado de Coment√°rios"
branch: "feat/extract-commentaries-to-json"
pr: ""
github_issue: ""
due: null
---

## Contexto

O projeto Bible API possui um sistema robusto de scraping de coment√°rios dos Church Fathers atrav√©s do Firecrawl MCP, mas atualmente os dados s√£o salvos diretamente no banco de dados. Para fins de processamento em lote e an√°lise externa, √© necess√°rio extrair esses coment√°rios em formato JSON estruturado sem import√°-los para o banco de dados.

Este trabalho se baseia nos comandos j√° existentes:
- `demo_firecrawl_scraping` - Demonstra√ß√£o funcional de scraping
- `catena_firecrawl_mcp` - Implementa√ß√£o completa com Firecrawl MCP

### Documenta√ß√£o de Refer√™ncia
O agente deve consultar os seguintes documentos para entender o contexto completo:
- `FIRECRAWL_MCP_GUIDE.md` - Guia de integra√ß√£o do Firecrawl MCP
- `FIRECRAWL_WORKFLOW_GUIDE.md` - Workflow completo do Firecrawl
- `SCRAPING_CHECKLIST.md` - Checklist de vers√≠culos para scraping
- `firecrawl_sample_lk1_1.json` - Exemplo de JSON de sa√≠da esperado
- `test_single_commentary.json` - Outro exemplo de JSON de sa√≠da

### Comandos Dispon√≠veis para An√°lise
O agente deve analisar os seguintes comandos existentes:
- `data/management/commands/demo_firecrawl_scraping.py`
- `data/management/commands/catena_firecrawl_mcp.py`
- `data/management/commands/firecrawl_book_scraper.py` (pode ter problemas de sintaxe que precisam ser corrigidos)
- `data/management/commands/import_firecrawl_json.py`

### Valor para o sistema
- Permite processamento em lote de coment√°rios sem impactar o banco de dados
- Facilita an√°lise externa e migra√ß√£o de dados
- Mant√©m a estrutura de dados j√° validada do projeto

### Notas Importantes para o Agente
1. **Verifica√ß√£o de Consist√™ncia**: O agente deve verificar a consist√™ncia entre os documentos existentes e ajustar quaisquer diverg√™ncias antes de implementar
2. **Corre√ß√£o de Problemas**: Alguns comandos podem ter problemas de sintaxe ou erros que precisam ser corrigidos (ex: `firecrawl_book_scraper.py`)
3. **Fluxo Linear**: Certifique-se de que todos os documentos e comandos funcionem de forma linear e coerente antes de implementar novas funcionalidades
4. **Preserva√ß√£o de Estrutura**: Mantenha a estrutura de dados existente conforme demonstrada nos arquivos JSON de exemplo

## Objetivo e Crit√©rios de Aceite
- [ ] CA1 ‚Äî Modificar comando `catena_firecrawl_mcp` para suportar sa√≠da JSON
- [ ] CA2 ‚Äî Adicionar op√ß√µes `--output-json` e `--output-dir`
- [ ] CA3 ‚Äî Salvar coment√°rios em arquivos JSON estruturados
- [ ] CA4 ‚Äî Manter valida√ß√£o de qualidade dos coment√°rios existente
- [ ] CA5 ‚Äî N√£o tentar conex√£o com banco de dados quando em modo JSON
- [ ] CA6 ‚Äî Verificar e ajustar consist√™ncia entre documentos existentes de firecrawl
- [ ] CA7 ‚Äî Corrigir poss√≠veis problemas de sintaxe em comandos existentes
- [ ] CA8 ‚Äî Garantir que todos os comandos funcionem de forma linear e coerente

## Escopo / Fora do Escopo
- Inclui: Modifica√ß√£o do comando `catena_firecrawl_mcp`
- Inclui: Cria√ß√£o de m√©todo para salvar em JSON
- Inclui: Adi√ß√£o de novas op√ß√µes de linha de comando
- Inclui: Verifica√ß√£o e corre√ß√£o de consist√™ncia entre documentos existentes
- Inclui: Ajuste de poss√≠veis problemas de sintaxe em comandos existentes
- N√£o inclui: Altera√ß√µes no modelo de dados do banco
- N√£o inclui: Cria√ß√£o de novos comandos de scraping

## Impacto T√©cnico
**Contrato (OpenAPI)**: n√£o muda
**DB/Migrations**: n√£o afeta
**Throttle/Cache**: n√£o afeta
**Performance**: m√≠nimo impacto, apenas IO de arquivos
**Seguran√ßa**: n√£o afeta

### Impacto nos Documentos Existentes
- Verifica√ß√£o e ajuste de consist√™ncia entre documentos de firecrawl
- Potenciais corre√ß√µes de problemas de sintaxe em comandos existentes
- Atualiza√ß√£o da documenta√ß√£o para refletir mudan√ßas

## Plano de Testes
**API**: Testar comando com diferentes op√ß√µes
- `python manage.py catena_firecrawl_mcp --verse lk/1/1 --output-json --verbose`
- `python manage.py catena_firecrawl_mcp --chapter lk/1 --output-json --verbose`

**Dados**: Verificar estrutura dos arquivos JSON gerados
- Estrutura consistente com padr√£o definido
- Todos os campos necess√°rios presentes
- Valida√ß√£o de qualidade dos coment√°rios mantida

**Consist√™ncia**: Verificar que todos os documentos e comandos funcionam corretamente
- Todos os comandos de scraping existentes devem continuar funcionando
- Documentos de refer√™ncia devem estar consistentes entre si
- Estrutura dos arquivos JSON gerados deve corresponder aos exemplos existentes

## Observabilidade
- Logs de salvamento em JSON
- Contagem de coment√°rios extra√≠dos
- Erros de parsing ou valida√ß√£o
- Logs de verifica√ß√£o de consist√™ncia de documentos

## Rollout & Rollback
- Plano de ativa√ß√£o: Modifica√ß√£o do comando existente
- Crit√©rios de sucesso: Arquivos JSON gerados corretamente e todos os comandos funcionando
- Estrat√©gia de revers√£o: Reverter modifica√ß√µes no comando e restaurar consist√™ncia de documentos

## Implementa√ß√£o Detalhada

### 0. Verifica√ß√£o e Ajuste de Consist√™ncia (Pr√©-requisito)
Antes de implementar a nova funcionalidade, o agente deve:
1. Verificar a consist√™ncia entre todos os documentos de firecrawl mencionados
2. Identificar e corrigir quaisquer diverg√™ncias ou problemas de sintaxe
3. Garantir que todos os comandos existentes funcionem corretamente
4. Validar a estrutura dos arquivos JSON de exemplo existentes

### 1. Adicionar Op√ß√µes de Linha de Comando

### 1. Adicionar Op√ß√µes de Linha de Comando
No m√©todo `add_arguments` do comando `catena_firecrawl_mcp`:
```python
parser.add_argument(
    '--output-json',
    action='store_true',
    help='Save extracted data to JSON files instead of database'
)
parser.add_argument(
    '--output-dir',
    type=str,
    default='data/scraped/json',
    help='Directory to save JSON files'
)
```

### 2. Criar M√©todo para Salvar em JSON
```python
def save_commentaries_to_json(self, commentaries: List[ParsedCommentary],
                             book: str, chapter: int, verse: int):
    """Save commentaries to JSON file"""
    if not commentaries:
        return

    # Create output directory
    output_dir = Path(self.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Prepare data structure
    data = {
        'verse_reference': f"{book} {chapter}:{verse}",
        'verse_text': f"Texto do vers√≠culo {book} {chapter}:{verse}",
        'commentaries': [
            {
                'author': comm.author,
                'period': comm.period,
                'content': comm.content,
                'quality_score': comm.quality_score,
                'is_valid': comm.is_valid()
            }
            for comm in commentaries
        ]
    }

    # Save to JSON file
    filename = f"{book.lower()}_{chapter}_{verse}.json"
    filepath = output_dir / filename

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    if self.verbose:
        self.stdout.write(f"   üíæ Saved JSON: {filename}")
```

### 3. Atualizar M√©todo de Salvamento
No m√©todo `save_commentaries_to_db`, adicionar condi√ß√£o para usar JSON:
```python
def save_commentaries_to_db(self, commentaries: List[ParsedCommentary],
                           book: str, chapter: int, verse: int):
    """Save commentaries to database or JSON"""
    if getattr(self, 'output_json', False):
        self.save_commentaries_to_json(commentaries, book, chapter, verse)
        return

    # ... restante do c√≥digo original para salvar no DB
```

### 4. Estrutura do JSON de Sa√≠da
Seguir a estrutura demonstrada nos arquivos de exemplo existentes:

`firecrawl_sample_lk1_1.json`:
```json
{
  "verse_reference": "Luke 1:1",
  "verse_text": "Since many have taken in hand to set forth in order a declaration of those things which are most surely believed among us,",
  "commentaries": [
    {
      "author": "Ambrose",
      "period": "AD 340-397",
      "content": "Highlights the variety of gospel attempts and the importance of divine inspiration. Notes that many tried to write gospels, but not all were successful.",
      "theological_themes": ["Divine inspiration", "Gospel authenticity"],
      "cross_references": []
    }
    // ... mais coment√°rios
  ]
}
```

A estrutura deve incluir campos adicionais como `theological_themes` e `cross_references` que s√£o parte do modelo existente.

### 5. Estrutura de Diret√≥rios de Sa√≠da
```
data/
‚îî‚îÄ‚îÄ scraped/
    ‚îî‚îÄ‚îÄ json/
        ‚îú‚îÄ‚îÄ luke_1_1.json
        ‚îú‚îÄ‚îÄ luke_1_2.json
        ‚îú‚îÄ‚îÄ luke_1_3.json
        ‚îî‚îÄ‚îÄ ...
```

## Checklist Operacional (Autor)
- [ ] OpenAPI gerado/commitado em `docs/` (se houve mudan√ßa)
- [ ] `make fmt lint test` ok local
- [ ] CI verde (lint, migrations-check, tests, schema-diff)
- [ ] PR descreve impacto e rollback
- [ ] Todos os comandos de scraping existentes funcionam corretamente ap√≥s as modifica√ß√µes
- [ ] Documenta√ß√£o atualizada e consistente

## Checklist Operacional (Revisor)
- [ ] Contrato est√°vel ou deprecia√ß√£o formal
- [ ] Testes suficientes (felizes + erros + auth + throttle + pagina√ß√£o/ordena√ß√£o/filtros)
- [ ] Sem N+1; p95 dentro do or√ßamento
- [ ] Migrations pequenas e revers√≠veis
- [ ] Seguran√ßa: sem PII em logs; escopos e rate adequados
- [ ] Cache/invalida√ß√£o documentados
- [ ] Todos os documentos de refer√™ncia est√£o consistentes
- [ ] Comandos existentes continuam funcionando ap√≥s as modifica√ß√µes
